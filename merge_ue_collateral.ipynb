{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00403d33",
   "metadata": {},
   "source": [
    "## 1. Configuration and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f175d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "# Configuration\n",
    "CSV_FOLDER = r\"c:\\Users\\jonat\\Downloads\\_unique_csv_master\"\n",
    "OUTPUT_FOLDER = os.path.join(CSV_FOLDER, \"ESMA_UE_Collat_Merged\")\n",
    "\n",
    "# Create output folder if it doesn't exist\n",
    "os.makedirs(OUTPUT_FOLDER, exist_ok=True)\n",
    "\n",
    "print(f\"Source folder: {CSV_FOLDER}\")\n",
    "print(f\"Output folder: {OUTPUT_FOLDER}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528cfc5c",
   "metadata": {},
   "source": [
    "## 2. Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dff67dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_filename(filename):\n",
    "    \"\"\"\n",
    "    Parse ESMA filename to extract components.\n",
    "    \n",
    "    Filename format: 1_<ASSET_TYPE>_<CATEGORY>_<IDENTIFIER>_<DATE>_<SEQUENCE>.csv\n",
    "    Example: 1_RMB_UE_213800WQJJDCAN4BCO57N201901_2021-04-30_29907.csv\n",
    "    \n",
    "    Returns:\n",
    "        dict with keys: asset_type, category, identifier, date, sequence, filename\n",
    "        None if filename doesn't match expected pattern\n",
    "    \"\"\"\n",
    "    pattern = r'^1_(\\w+)_(UE|Collateral)_(.+)_(\\d{4}-\\d{2}-\\d{2})_(\\d+)\\.csv$'\n",
    "    match = re.match(pattern, filename)\n",
    "    \n",
    "    if match:\n",
    "        return {\n",
    "            'asset_type': match.group(1),\n",
    "            'category': match.group(2),\n",
    "            'identifier': match.group(3),\n",
    "            'date': match.group(4),\n",
    "            'sequence': match.group(5),\n",
    "            'filename': filename\n",
    "        }\n",
    "    return None\n",
    "\n",
    "\n",
    "def create_merged_filename(ue_filename):\n",
    "    \"\"\"\n",
    "    Convert UE filename to merged filename.\n",
    "    \n",
    "    Example: 1_RMB_UE_xxx.csv -> 1_RMB_UE_Collateral_xxx.csv\n",
    "    \"\"\"\n",
    "    return ue_filename.replace('_UE_', '_UE_Collateral_')\n",
    "\n",
    "\n",
    "def detect_merge_keys(ue_columns, collateral_columns):\n",
    "    \"\"\"\n",
    "    Auto-detect the correct merge key columns based on available columns.\n",
    "    \n",
    "    Looks for columns ending in 'L2' (UE) and 'C2' (Collateral) that share\n",
    "    the same prefix pattern (e.g., RREL2/RREC2, NPEL2/NPEC2, CRPL2/CRPC2).\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (ue_key, collateral_key) or (None, None) if no match found\n",
    "    \"\"\"\n",
    "    # Find all potential key columns (ending in L2 or C2, max 6 chars)\n",
    "    ue_l2_cols = [c for c in ue_columns if c.endswith('L2') and len(c) <= 6]\n",
    "    coll_c2_cols = [c for c in collateral_columns if c.endswith('C2') and len(c) <= 6]\n",
    "    \n",
    "    # Try to match by prefix pattern\n",
    "    # RREL2 -> RRE -> RREC2\n",
    "    # NPEL2 -> NPE -> NPEC2\n",
    "    # CRPL2 -> CRP -> CRPC2\n",
    "    for ue_col in ue_l2_cols:\n",
    "        prefix = ue_col[:-2]  # Remove 'L2' -> e.g., 'RRE', 'NPE', 'CRP'\n",
    "        expected_coll = prefix[:-1] + 'C2'  # Replace last char with 'C2'\n",
    "        \n",
    "        if expected_coll in coll_c2_cols:\n",
    "            return ue_col, expected_coll\n",
    "    \n",
    "    return None, None\n",
    "\n",
    "\n",
    "def get_columns_to_drop(collateral_columns, collateral_key):\n",
    "    \"\"\"\n",
    "    Determine which columns to drop from collateral before merge.\n",
    "    \n",
    "    Drops:\n",
    "    - Sec_Id and Pool_Cutoff_Date (already in UE)\n",
    "    - Security identifier columns (*C1) to avoid duplication with *L1\n",
    "    \"\"\"\n",
    "    cols_to_drop = ['Sec_Id', 'Pool_Cutoff_Date']\n",
    "    \n",
    "    # Find and drop *C1 columns (security identifiers)\n",
    "    c1_cols = [c for c in collateral_columns if c.endswith('C1') and len(c) <= 6]\n",
    "    cols_to_drop.extend(c1_cols)\n",
    "    \n",
    "    # Return only columns that actually exist\n",
    "    return [c for c in cols_to_drop if c in collateral_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc285f3",
   "metadata": {},
   "source": [
    "## 3. Main Merge Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eddb8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_ue_collateral(ue_path, collateral_path):\n",
    "    \"\"\"\n",
    "    Merge a UE file with its corresponding Collateral file.\n",
    "    \n",
    "    Process:\n",
    "    1. Load both files\n",
    "    2. Auto-detect the correct merge key columns\n",
    "    3. Convert merge keys to string (prevents type mismatch errors)\n",
    "    4. Remove duplicate metadata columns from collateral\n",
    "    5. Perform left join on loan identifier\n",
    "    \n",
    "    Args:\n",
    "        ue_path: Full path to UE CSV file\n",
    "        collateral_path: Full path to Collateral CSV file\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (merged_dataframe, statistics_dict)\n",
    "        \n",
    "    Raises:\n",
    "        ValueError: If no valid merge keys can be detected\n",
    "    \"\"\"\n",
    "    # Load files with low_memory=False to ensure consistent dtypes\n",
    "    ue_df = pd.read_csv(ue_path, low_memory=False)\n",
    "    collateral_df = pd.read_csv(collateral_path, low_memory=False)\n",
    "    \n",
    "    # Detect merge keys based on column names\n",
    "    ue_key, collateral_key = detect_merge_keys(\n",
    "        ue_df.columns.tolist(), \n",
    "        collateral_df.columns.tolist()\n",
    "    )\n",
    "    \n",
    "    if ue_key is None:\n",
    "        ue_l2 = [c for c in ue_df.columns if 'L2' in c]\n",
    "        coll_c2 = [c for c in collateral_df.columns if 'C2' in c]\n",
    "        raise ValueError(\n",
    "            f\"Cannot detect merge keys. \"\n",
    "            f\"UE *L2 columns: {ue_l2}, \"\n",
    "            f\"Collateral *C2 columns: {coll_c2}\"\n",
    "        )\n",
    "    \n",
    "    # Convert merge keys to string to prevent type mismatch\n",
    "    # (some files have numeric IDs, others have string IDs)\n",
    "    ue_df[ue_key] = ue_df[ue_key].astype(str)\n",
    "    collateral_df[collateral_key] = collateral_df[collateral_key].astype(str)\n",
    "    \n",
    "    # Prepare collateral for merge - remove duplicate columns\n",
    "    cols_to_drop = get_columns_to_drop(collateral_df.columns.tolist(), collateral_key)\n",
    "    collateral_for_merge = collateral_df.drop(columns=cols_to_drop)\n",
    "    \n",
    "    # Perform left join\n",
    "    # Left join preserves all UE rows; collateral columns are NaN if no match\n",
    "    merged_df = pd.merge(\n",
    "        ue_df,\n",
    "        collateral_for_merge,\n",
    "        left_on=ue_key,\n",
    "        right_on=collateral_key,\n",
    "        how='left',\n",
    "        suffixes=('', '_collateral')\n",
    "    )\n",
    "    \n",
    "    # Calculate statistics\n",
    "    stats = {\n",
    "        'ue_rows': len(ue_df),\n",
    "        'collateral_rows': len(collateral_df),\n",
    "        'merged_rows': len(merged_df),\n",
    "        'merged_cols': len(merged_df.columns),\n",
    "        'matched_rows': merged_df[collateral_key].notna().sum(),\n",
    "        'unmatched_rows': merged_df[collateral_key].isna().sum(),\n",
    "        'merge_keys': f\"{ue_key}={collateral_key}\"\n",
    "    }\n",
    "    \n",
    "    return merged_df, stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43079bd6",
   "metadata": {},
   "source": [
    "## 4. Find Matching File Pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c242d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all CSV files starting with '1_'\n",
    "all_files = [f for f in os.listdir(CSV_FOLDER) if f.endswith('.csv') and f.startswith('1_')]\n",
    "\n",
    "# Separate UE and Collateral files\n",
    "ue_files = [f for f in all_files if '_UE_' in f]\n",
    "collateral_files = [f for f in all_files if '_Collateral_' in f]\n",
    "\n",
    "print(f\"Total CSV files found: {len(all_files)}\")\n",
    "print(f\"UE files: {len(ue_files)}\")\n",
    "print(f\"Collateral files: {len(collateral_files)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa682a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse all filenames\n",
    "ue_parsed = [parse_filename(f) for f in ue_files]\n",
    "ue_parsed = [p for p in ue_parsed if p is not None]  # Remove failed parses\n",
    "\n",
    "collateral_parsed = [parse_filename(f) for f in collateral_files]\n",
    "collateral_parsed = [p for p in collateral_parsed if p is not None]\n",
    "\n",
    "print(f\"Successfully parsed UE files: {len(ue_parsed)}\")\n",
    "print(f\"Successfully parsed Collateral files: {len(collateral_parsed)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914438c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lookup dictionary for collateral files\n",
    "# Key: (asset_type, identifier, date) -> ensures we match same asset type\n",
    "collateral_lookup = {\n",
    "    (p['asset_type'], p['identifier'], p['date']): p \n",
    "    for p in collateral_parsed\n",
    "}\n",
    "\n",
    "# Find matching pairs\n",
    "matching_pairs = []\n",
    "for ue in ue_parsed:\n",
    "    key = (ue['asset_type'], ue['identifier'], ue['date'])\n",
    "    if key in collateral_lookup:\n",
    "        matching_pairs.append({\n",
    "            'ue': ue,\n",
    "            'collateral': collateral_lookup[key]\n",
    "        })\n",
    "\n",
    "# Count pairs by asset type\n",
    "pairs_by_type = Counter(p['ue']['asset_type'] for p in matching_pairs)\n",
    "\n",
    "print(f\"\\nMatching UE-Collateral pairs found: {len(matching_pairs)}\")\n",
    "print(f\"\\nBreakdown by asset type:\")\n",
    "for asset_type, count in sorted(pairs_by_type.items()):\n",
    "    print(f\"  {asset_type}: {count} pairs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f77ddb",
   "metadata": {},
   "source": [
    "## 5. Execute Batch Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c14f070",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"BATCH MERGE: UE + COLLATERAL FILES\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nTotal pairs to process: {len(matching_pairs)}\")\n",
    "print(f\"Output folder: {OUTPUT_FOLDER}\")\n",
    "print(\"\\nStarting merge process...\\n\")\n",
    "\n",
    "# Track results\n",
    "successful = 0\n",
    "failed = 0\n",
    "failed_pairs = []\n",
    "all_stats = []\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for pair in tqdm(matching_pairs, desc=\"Merging files\"):\n",
    "    ue_filename = pair['ue']['filename']\n",
    "    collateral_filename = pair['collateral']['filename']\n",
    "    \n",
    "    ue_path = os.path.join(CSV_FOLDER, ue_filename)\n",
    "    collateral_path = os.path.join(CSV_FOLDER, collateral_filename)\n",
    "    \n",
    "    try:\n",
    "        # Merge the files\n",
    "        merged_df, stats = merge_ue_collateral(ue_path, collateral_path)\n",
    "        \n",
    "        # Create output filename and save\n",
    "        merged_filename = create_merged_filename(ue_filename)\n",
    "        output_path = os.path.join(OUTPUT_FOLDER, merged_filename)\n",
    "        merged_df.to_csv(output_path, index=False)\n",
    "        \n",
    "        # Record statistics\n",
    "        stats['filename'] = merged_filename\n",
    "        stats['asset_type'] = pair['ue']['asset_type']\n",
    "        all_stats.append(stats)\n",
    "        \n",
    "        successful += 1\n",
    "        \n",
    "    except Exception as e:\n",
    "        failed += 1\n",
    "        failed_pairs.append({\n",
    "            'ue': ue_filename,\n",
    "            'collateral': collateral_filename,\n",
    "            'error': str(e)\n",
    "        })\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\n\" + \"=\"*80)\n",
    "print(\"MERGE COMPLETE\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nTime elapsed: {elapsed_time:.1f} seconds\")\n",
    "print(f\"Successful: {successful}\")\n",
    "print(f\"Failed: {failed}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a4a841",
   "metadata": {},
   "source": [
    "## 6. Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4066aec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if all_stats:\n",
    "    # Summary by asset type\n",
    "    print(\"SUCCESSFUL MERGES BY ASSET TYPE\")\n",
    "    print(\"-\"*40)\n",
    "    success_by_type = Counter(s['asset_type'] for s in all_stats)\n",
    "    for asset_type, count in sorted(success_by_type.items()):\n",
    "        print(f\"  {asset_type}: {count} files\")\n",
    "    \n",
    "    # Merge keys used\n",
    "    print(f\"\\nMERGE KEYS USED\")\n",
    "    print(\"-\"*40)\n",
    "    keys_used = Counter(s['merge_keys'] for s in all_stats)\n",
    "    for key, count in keys_used.most_common():\n",
    "        print(f\"  {key}: {count} files\")\n",
    "    \n",
    "    # Row statistics\n",
    "    total_ue_rows = sum(s['ue_rows'] for s in all_stats)\n",
    "    total_merged_rows = sum(s['merged_rows'] for s in all_stats)\n",
    "    total_matched = sum(s['matched_rows'] for s in all_stats)\n",
    "    \n",
    "    print(f\"\\nROW STATISTICS\")\n",
    "    print(\"-\"*40)\n",
    "    print(f\"  Total UE rows processed: {total_ue_rows:,}\")\n",
    "    print(f\"  Total merged rows: {total_merged_rows:,}\")\n",
    "    print(f\"  Rows with collateral match: {total_matched:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1215951",
   "metadata": {},
   "outputs": [],
   "source": [
    "if failed_pairs:\n",
    "    print(\"FAILED MERGES\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Group by error type\n",
    "    error_types = Counter(p['error'][:80] for p in failed_pairs)\n",
    "    \n",
    "    print(f\"\\nError summary:\")\n",
    "    for error, count in error_types.most_common():\n",
    "        print(f\"  {count}x: {error}...\")\n",
    "    \n",
    "    print(f\"\\nFailed files:\")\n",
    "    for i, fp in enumerate(failed_pairs, 1):\n",
    "        print(f\"\\n{i}. UE: {fp['ue']}\")\n",
    "        print(f\"   Collateral: {fp['collateral']}\")\n",
    "        print(f\"   Error: {fp['error']}\")\n",
    "else:\n",
    "    print(\"All files merged successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5678aab9",
   "metadata": {},
   "source": [
    "## 7. Verification (Optional)\n",
    "\n",
    "Run this cell to verify a random merged file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ca16bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "if all_stats:\n",
    "    # Pick a random successful merge to verify\n",
    "    sample = random.choice(all_stats)\n",
    "    sample_file = sample['filename']\n",
    "    \n",
    "    print(f\"VERIFICATION: {sample_file}\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Load merged file\n",
    "    merged_path = os.path.join(OUTPUT_FOLDER, sample_file)\n",
    "    merged_df = pd.read_csv(merged_path, nrows=5)\n",
    "    \n",
    "    print(f\"\\nMerge statistics:\")\n",
    "    print(f\"  UE rows: {sample['ue_rows']}\")\n",
    "    print(f\"  Collateral rows: {sample['collateral_rows']}\")\n",
    "    print(f\"  Merged rows: {sample['merged_rows']}\")\n",
    "    print(f\"  Matched rows: {sample['matched_rows']}\")\n",
    "    print(f\"  Merge keys: {sample['merge_keys']}\")\n",
    "    \n",
    "    print(f\"\\nColumn count: {len(merged_df.columns)}\")\n",
    "    print(f\"\\nFirst 5 rows (selected columns):\")\n",
    "    \n",
    "    # Show key columns\n",
    "    key_cols = ['Sec_Id', 'Pool_Cutoff_Date']\n",
    "    key_cols.extend([c for c in merged_df.columns if c.endswith('L2') or c.endswith('C2')][:4])\n",
    "    key_cols = [c for c in key_cols if c in merged_df.columns]\n",
    "    \n",
    "    display(merged_df[key_cols])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
